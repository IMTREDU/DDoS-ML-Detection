{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13608817",
   "metadata": {},
   "source": [
    "# CICDDoS2019 Dataset\n",
    "\n",
    "This notebook reproduces the same supervised learning pipeline described in the paper, excluding SVM.\n",
    "\n",
    "Models included: Random Forest, KNN, Logistic Regression, Decision Tree.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ddb9572",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f15049",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    classification_report,\n",
    "    confusion_matrix\n",
    ")\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "print(\"Libraries imported successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64100a8b",
   "metadata": {},
   "source": [
    "### Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9287dfd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try common paths so the notebook works both locally and in shared environments\n",
    "candidate_paths = [\n",
    "    \"../DataSets/cicddos2019.csv\",\n",
    "    \"./cicddos2019.csv\",\n",
    "    \"/mnt/data/cicddos2019.csv\",\n",
    "]\n",
    "\n",
    "csv_path = None\n",
    "for p in candidate_paths:\n",
    "    if os.path.exists(p):\n",
    "        csv_path = p\n",
    "        break\n",
    "\n",
    "if csv_path is None:\n",
    "    raise FileNotFoundError(\n",
    "        \"Could not find cicddos2019.csv. Put it in the same folder as this notebook, \"\n",
    "        \"or in ../DataSets/, or update candidate_paths.\"\n",
    "    )\n",
    "\n",
    "df = pd.read_csv(csv_path, low_memory=False)\n",
    "\n",
    "print(f\"Loaded dataset from: {csv_path}\")\n",
    "print(f\"Original Dataset Shape: {df.shape}\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e954232",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300f4692",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Shape before cleaning: {df.shape}\")\n",
    "\n",
    "# 1) Clean column names\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "# Drop any accidental index columns like 'Unnamed: 0'\n",
    "unnamed_cols = [c for c in df.columns if c.lower().startswith('unnamed')]\n",
    "if unnamed_cols:\n",
    "    df.drop(columns=unnamed_cols, inplace=True)\n",
    "\n",
    "# 2) Handle infinite and missing values\n",
    "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# 3) Remove duplicates\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "print(f\"Shape after cleaning: {df.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a3c259",
   "metadata": {},
   "source": [
    "### Label Encoding (Binary: Benign vs Attack)\n",
    "\n",
    "CICDDoS2019 often includes a `Class` column (Benign/Attack) and a `Label` column (attack type).\n",
    "We convert to a simple binary target:\n",
    "- 0 = Benign\n",
    "- 1 = Attack\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361cf154",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary encoding using 'Class': 0 = Benign, 1 = Attack\n",
    "df['Label'] = (df['Class'].astype(str).str.strip().str.lower() != 'benign').astype(int)\n",
    "\n",
    "# Drop the original text label column after encoding\n",
    "df.drop(columns=['Class'], inplace=True)\n",
    "\n",
    "print(\"Label mapping: 0 = Benign, 1 = Attack\")\n",
    "print(df['Label'].value_counts().rename({0: \"Benign\", 1: \"Attack\"}))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16037bb",
   "metadata": {},
   "source": [
    "### Feature Reduction and Train/Test Split (70/30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1457a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('Label', axis=1)\n",
    "y = df['Label']\n",
    "\n",
    "# Keep only numeric features (this drops Timestamp if it is text)\n",
    "X = X.select_dtypes(include=[np.number])\n",
    "\n",
    "print(f\"Numeric feature count: {X.shape[1]}\")\n",
    "print(\"Class distribution (full dataset):\")\n",
    "print(y.value_counts().rename({0: \"Benign\", 1: \"Attack\"}))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.30,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "print(\"\\nTrain shape:\", X_train.shape, \"Test shape:\", X_test.shape)\n",
    "print(\"Train distribution:\")\n",
    "print(y_train.value_counts().rename({0: \"Benign\", 1: \"Attack\"}))\n",
    "print(\"Test distribution:\")\n",
    "print(y_test.value_counts().rename({0: \"Benign\", 1: \"Attack\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d910515",
   "metadata": {},
   "source": [
    "### Normalization (StandardScaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4abe15",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"Normalization complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7598792",
   "metadata": {},
   "source": [
    "### Handling Class Imbalance (SMOTE)\n",
    "\n",
    "SMOTE is applied to the training set only, to avoid leaking information from the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5701fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE(random_state=42)\n",
    "\n",
    "X_train_balanced, y_train_balanced = smote.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "print(\"After SMOTE (training only):\")\n",
    "print(\"X_train_balanced shape:\", X_train_balanced.shape)\n",
    "print(\"y_train_balanced distribution:\")\n",
    "print(pd.Series(y_train_balanced).value_counts().rename({0: \"Benign\", 1: \"Attack\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47388ebd",
   "metadata": {},
   "source": [
    "### Feature Selection using PCA\n",
    "\n",
    "PCA is fitted on the (scaled, balanced) training features, then applied to the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa695010",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=0.95, random_state=42)\n",
    "\n",
    "X_train_pca = pca.fit_transform(X_train_balanced)\n",
    "X_test_pca = pca.transform(X_test_scaled)\n",
    "\n",
    "print(f\"Original feature count: {X.shape[1]}\")\n",
    "print(f\"PCA components kept: {X_train_pca.shape[1]}\")\n",
    "print(f\"Explained variance (sum): {pca.explained_variance_ratio_.sum():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ed0ba5",
   "metadata": {},
   "source": [
    "### Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92414cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Standard defaults similar to the previous notebook\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(\"Training Random Forest...\")\n",
    "rf_model.fit(X_train_pca, y_train_balanced)\n",
    "\n",
    "print(\"Predicting on Test Set...\")\n",
    "y_pred_rf = rf_model.predict(X_test_pca)\n",
    "\n",
    "# Evaluate Performance\n",
    "rf_accuracy = accuracy_score(y_test, y_pred_rf)\n",
    "rf_precision = precision_score(y_test, y_pred_rf)\n",
    "rf_recall = recall_score(y_test, y_pred_rf)\n",
    "rf_f1 = f1_score(y_test, y_pred_rf)\n",
    "\n",
    "print(\"RANDOM FOREST RESULTS\")\n",
    "print(f\"Accuracy:  {rf_accuracy:.4f}\")\n",
    "print(f\"Precision: {rf_precision:.4f}\")\n",
    "print(f\"Recall:    {rf_recall:.4f}\")\n",
    "print(f\"F1-Score:  {rf_f1:.4f}\")\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_rf, target_names=[\"Benign\", \"Attack\"]))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_rf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b257d136",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validation on training data (optional, can take some time)\n",
    "rf_scores = cross_val_score(rf_model, X_train_pca, y_train_balanced, cv=3, scoring=\"accuracy\")\n",
    "print(\"Random Forest CV scores:\", rf_scores)\n",
    "print(\"Mean CV accuracy:\", rf_scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048a85e6",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbours (KNN) Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ef06ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "print(\"Training KNN...\")\n",
    "knn_model.fit(X_train_pca, y_train_balanced)\n",
    "\n",
    "print(\"Predicting on Test Set...\")\n",
    "y_pred_knn = knn_model.predict(X_test_pca)\n",
    "\n",
    "# Evaluate Performance\n",
    "knn_accuracy = accuracy_score(y_test, y_pred_knn)\n",
    "knn_precision = precision_score(y_test, y_pred_knn)\n",
    "knn_recall = recall_score(y_test, y_pred_knn)\n",
    "knn_f1 = f1_score(y_test, y_pred_knn)\n",
    "\n",
    "print(\"KNN RESULTS\")\n",
    "print(f\"Accuracy:  {knn_accuracy:.4f}\")\n",
    "print(f\"Precision: {knn_precision:.4f}\")\n",
    "print(f\"Recall:    {knn_recall:.4f}\")\n",
    "print(f\"F1-Score:  {knn_f1:.4f}\")\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_knn, target_names=[\"Benign\", \"Attack\"]))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_knn))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333338f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_scores = cross_val_score(knn_model, X_train_pca, y_train_balanced, cv=3, scoring=\"accuracy\")\n",
    "print(\"KNN CV scores:\", knn_scores)\n",
    "print(\"Mean CV accuracy:\", knn_scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d293e2",
   "metadata": {},
   "source": [
    "### Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d0253e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Keep it simple, increase max_iter for convergence\n",
    "lr_model = LogisticRegression(max_iter=2000, n_jobs=-1)\n",
    "\n",
    "print(\"Training Logistic Regression...\")\n",
    "lr_model.fit(X_train_pca, y_train_balanced)\n",
    "\n",
    "print(\"Predicting on Test Set...\")\n",
    "y_pred_lr = lr_model.predict(X_test_pca)\n",
    "\n",
    "# Evaluate Performance\n",
    "lr_accuracy = accuracy_score(y_test, y_pred_lr)\n",
    "lr_precision = precision_score(y_test, y_pred_lr)\n",
    "lr_recall = recall_score(y_test, y_pred_lr)\n",
    "lr_f1 = f1_score(y_test, y_pred_lr)\n",
    "\n",
    "print(\"LOGISTIC REGRESSION RESULTS\")\n",
    "print(f\"Accuracy:  {lr_accuracy:.4f}\")\n",
    "print(f\"Precision: {lr_precision:.4f}\")\n",
    "print(f\"Recall:    {lr_recall:.4f}\")\n",
    "print(f\"F1-Score:  {lr_f1:.4f}\")\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_lr, target_names=[\"Benign\", \"Attack\"]))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_lr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c928ebc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_scores = cross_val_score(lr_model, X_train_pca, y_train_balanced, cv=3, scoring=\"accuracy\")\n",
    "print(\"Logistic Regression CV scores:\", lr_scores)\n",
    "print(\"Mean CV accuracy:\", lr_scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea828244",
   "metadata": {},
   "source": [
    "### Decision Tree Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf9c5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt_model = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "print(\"Training Decision Tree...\")\n",
    "dt_model.fit(X_train_pca, y_train_balanced)\n",
    "\n",
    "print(\"Predicting on Test Set...\")\n",
    "y_pred_dt = dt_model.predict(X_test_pca)\n",
    "\n",
    "# Evaluate Performance\n",
    "dt_accuracy = accuracy_score(y_test, y_pred_dt)\n",
    "dt_precision = precision_score(y_test, y_pred_dt)\n",
    "dt_recall = recall_score(y_test, y_pred_dt)\n",
    "dt_f1 = f1_score(y_test, y_pred_dt)\n",
    "\n",
    "print(\"DECISION TREE RESULTS\")\n",
    "print(f\"Accuracy:  {dt_accuracy:.4f}\")\n",
    "print(f\"Precision: {dt_precision:.4f}\")\n",
    "print(f\"Recall:    {dt_recall:.4f}\")\n",
    "print(f\"F1-Score:  {dt_f1:.4f}\")\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_dt, target_names=[\"Benign\", \"Attack\"]))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_dt))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973271c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_scores = cross_val_score(dt_model, X_train_pca, y_train_balanced, cv=3, scoring=\"accuracy\")\n",
    "print(\"Decision Tree CV scores:\", dt_scores)\n",
    "print(\"Mean CV accuracy:\", dt_scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc1dfe90",
   "metadata": {},
   "source": [
    "### Summary Table (All Models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7a2d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame([\n",
    "    {\"Model\": \"Random Forest\",       \"Accuracy\": rf_accuracy,  \"Precision\": rf_precision,  \"Recall\": rf_recall,  \"F1\": rf_f1},\n",
    "    {\"Model\": \"KNN\",                 \"Accuracy\": knn_accuracy, \"Precision\": knn_precision, \"Recall\": knn_recall, \"F1\": knn_f1},\n",
    "    {\"Model\": \"Logistic Regression\", \"Accuracy\": lr_accuracy,  \"Precision\": lr_precision,  \"Recall\": lr_recall,  \"F1\": lr_f1},\n",
    "    {\"Model\": \"Decision Tree\",       \"Accuracy\": dt_accuracy,  \"Precision\": dt_precision,  \"Recall\": dt_recall,  \"F1\": dt_f1},\n",
    "]).sort_values(\"Accuracy\", ascending=False)\n",
    "\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4286aaa",
   "metadata": {},
   "source": [
    "### Optional: Accuracy Bar Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb73ae9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,4))\n",
    "plt.bar(results_df[\"Model\"], results_df[\"Accuracy\"])\n",
    "plt.xticks(rotation=20, ha=\"right\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Accuracy Comparison (CICDDoS2019)\")\n",
    "plt.ylim(0, 1)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
